
///// PREFILTER CONFIG
prefilterConfig {

  input {
    topic: "radius"
    //topic: "radius_test"

  }

  output {
    topicCon: "radiusConLog",
    topicLoad: "radiusLoadLog",
    topicError: "raidusErroLog"
    //topicCon: "radiusConLog_test",
    //topicLoad: "radiusLoadLog_test",
    //topicError: "raidusErroLog_test"
  }


  stopWords: ["a", "an", "the"]

  windowDuration: 10s

  slideDuration: 10s

  sparkConfig {
    "spark.master": "yarn"
    //"spark.master": "local[2]"
    "spark.app.name": "prefilter-Radius-Log"
    "spark.streaming.kafka.maxRatePerPartition" : "1000"
    //es test
    //"es.port": "9200"
    //"es.nodes":"localhost"
    //"es.http.timeout":"5m"
    //"es.scroll.size":"50"
    //"es.index.auto.create":"true"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

  streamingBatchDuration: 5s

  //streamingCheckPointDir: ${java.io.tmpdir}
  streamingCheckPointDir: "/data/kafka/checkpoint/prefilter"


  sourceKafka {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
    //"bootstrap.servers": "localhost"
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    "group.id": "raidus-streaming-log"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"

  }

  prefilterSinkKafka {
    // kafka bootstrap
    //"bootstrap.servers": "localhost:9092"
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    // ack from all in-sync replicas
    "acks": "all"
    // reduce buffer size from default 32M to 8M
    "buffer.memory": "8388608"
    // block if buffer is full
    "block.on.buffer.full": "true"
    // retry forever
    "retries": "2147483647"
    "retry.backoff.ms": "1500"
    //String Se-De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    "key.serializer" : "org.apache.kafka.common.serialization.StringSerializer"
    "value.serializer": "org.apache.kafka.common.serialization.StringSerializer"

    // Byte Array
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
  }

}
//
//
// CONN CONFIG
connConfig {
  //Kafka input topic
  input {
    topic: "radiusConLog"
    //topic: "radiusConLog_test"

  }

  sparkConfig {
    //PROD
    "spark.master": "yarn"
    //LOCAL
    //"spark.master": "local[2]"
    "spark.app.name": "connLog-Radius"
    // mongo config
    //"spark.mongodb.output.uri" : "mongodb://172.27.11.146:27017/radius.conn_counting"
    //"spark.mongodb.output.uri" : "mongodb://localhost:27017/radius.conn_counting"
    // cassandra config
    "spark.cassandra.connection.host" : "172.27.11.156"
    "spark.cassandra.output.batch.size.rows" : "auto"
    //"spark.cassandra.username"
    //"spark.cassandra.password"
    //USING THIS CONFIG AFTER RESTART JOB
    //"spark.streaming.kafka.maxRatePerPartition" : "100"
    //STABLE MODE.
    "spark.streaming.kafka.maxRatePerPartition" : "300"
    //es test
    "es.port": "9200"
    "es.nodes":"172.27.11.156"
    "es.http.timeout":"5m"
    "es.scroll.size":"50"
    "es.index.auto.create":"true"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

//  windowDuration: 120s
//  slideDuration: 120s
//  streamingBatchDuration: 60s
  radiusAnomalyDetectionKafkaTopic : "anomalydetection"
  windowDuration: 180s
  slideDuration: 90s
  streamingBatchDuration: 90s
  //windowDuration: 180s
  //slideDuration: 180s
  //windowDuration: 10s

  //slideDuration: 10s

  //streamingBatchDuration: 5s

  //streamingCheckPointDir: ${java.io.tmpdir}
  //streamingCheckpointDir: "/tmp"
  streamingCheckPointDir: "/data/kafka/checkpoint/connLog"
  //streamingCheckPointDir: "/tmp/streamingCheckPoint6"

  sourceKafka {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    //"bootstrap.servers": "localhost:9092"
    "group.id": "raidus-streaming-log"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"

  }

  anomalySinkKafka {
    // kafka bootstrap
    //"bootstrap.servers": "localhost:9092"
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    // ack from all in-sync replicas
    "acks": "all"
    // reduce buffer size from default 32M to 8M
    "buffer.memory": "8388608"
    // block if buffer is full
    "block.on.buffer.full": "true"
    // retry forever
    "retries": "2147483647"
    "retry.backoff.ms": "1500"
    //String Se-De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    "key.serializer" : "org.apache.kafka.common.serialization.StringSerializer"
    "value.serializer": "org.apache.kafka.common.serialization.StringSerializer"

    // Byte Array
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
  }

  cassandraStorage{
    "keySpace" : "radius"
    "table" : "connlog"
  }
  mongoStorage{
    "write.mode":"append"
  }
  powerBIConfig{
    //"bras_dataset_url":"https://api.powerbi.com/beta/4ebc9261-871a-44c5-93a5-60eb590917cd/datasets/e654c506-58c3-42ae-ac37-ddf4fd4ca8d0/rows?key=nrB25hj7BRJZ95pRBSnUiF0QOAGzHkU8i67bcLr%2FAUGiNykfVC%2Bp6yHGxd5Eop4pKpf0Qz4dxWdGPPc7fFRrZg%3D%3D"
    "bras_dataset_url":"https://api.powerbi.com/beta/4ebc9261-871a-44c5-93a5-60eb590917cd/datasets/b62431b5-e77b-4e00-a100-df5f61fcd273/rows?key=m9uGpnXiQAjlZitkd7%2FDZb6RWs1tf5pt2x%2FV7jASBFKfe0aBJEPDRz9hvSWVfik3DhHTqOHLNYP2NYiEr9dSAQ%3D%3D"
    "bras_sumcount_dataset_url":"https://api.powerbi.com/beta/4ebc9261-871a-44c5-93a5-60eb590917cd/datasets/fe2af8f6-da63-4746-8a13-cf388d0b14a8/rows?key=KjN77LjanVtlQe3EFR%2FvY6wHcAvhFtkrgaq3TQXjkO423QO8hr9HgILI4l7eP3EObZ%2FAcT02aMYcR304GVuUCw%3D%3D"
    "inf_dataset_url" :""
    "inf_sumcount_dataset_url":"url hear!"
    "proxy_host":"172.30.45.220"
  }
  postgresStorage{
    //"jdbcUsername" : "postgres"
    //"jdbcPassword" : "hung"
    //"jdbcHostname" : "localhost"
    //"jdbcPort"     : "5432"
    //"jdbcDatabase" : "big_data"
       "jdbcUsername" : "infdb"
       //"jdbcUsername" : "rawlog_fe"
       "jdbcPassword" : "inf@db170120"
       //"jdbcPassword" : "Pankjha2jW9JAh5"
       //"jdbcHostname" : "172.27.11.151"
       "jdbcHostname" : "172.27.11.151"
      // "jdbcHostname" : "172.27.11.9"
       "jdbcPort"     : "5432"
       "jdbcDatabase" : "inf_db"
       "jdbcHostnameForRead" : "172.27.11.151"
       //"jdbcHostnameForRead" : "172.27.11.152"
       "jdbcDatabaseForRead" : "big_data"
       "jdbcUsernameForRead" : "big_data_query"
       "jdbcPasswordForRead" : "bdquery"



//        "jdbcUsername" : "big_data_query"
//        "jdbcPassword" : "bdquery"
//        "jdbcHostname" : "172.27.11.152"
//        "jdbcPort"     : "5432"
//        "jdbcDatabase" : "big_data"
  }

}
//
//
//IMPORT TO POSTGRES FROM ES
importPostgresConfig{
  esConfig{
    bras-prefix: "bras"
    inf-prefix: "inf"
  }
  postgresConfig{
    "jdbcUsername" : "infdb"
    //"jdbcUsername" : "rawlog_fe"
    "jdbcPassword" : "inf@db170120"
    //"jdbcPassword" : "Pankjha2jW9JAh5"
    //"jdbcHostname" : "172.27.11.151"
    "jdbcHostname" : "172.27.11.151"
    // "jdbcHostname" : "172.27.11.9"
    "jdbcPort"     : "5432"
    "jdbcDatabase" : "inf_db"
    "jdbcHostnameForRead" : "172.27.11.151"
    //"jdbcHostnameForRead" : "172.27.11.152"
    "jdbcDatabaseForRead" : "big_data"
    "jdbcUsernameForRead" : "big_data_query"
    "jdbcPasswordForRead" : "bdquery"
  }
  sparkConfig{
    "spark.master": "yarn"
    "spark.app.name": "connLog-Import-data-From-Es-to-Postgres"
    //STABLE MODE.
    //"spark.streaming.kafka.maxRatePerPartition" : "300"
    //es test
    "es.port": "9200"
    "es.nodes":"172.27.11.156"
    "es.http.timeout":"5m"
    "es.scroll.size":"50"
    "es.index.auto.create":"true"
    "es.query":"?q=me*"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

}
//
//
//  ANOMALY DETECTION
anomalyConfig {
  //Kafka input topic
  inputTopic: "empty-topic"
  //inputTopic: "anomalydetection"

  sparkConfig {
    "spark.master": "local[2]"
    //"spark.master": "yarn"
    "spark.app.name": "anomaly-detection-Radius"
    // mongo config
    //"spark.mongodb.output.uri" : "mongodb://172.27.11.146:27017/radius.conn_counting"
    //"spark.mongodb.output.uri" : "mongodb://localhost:27017/radius.conn_counting"
    // cassandra config
    "spark.cassandra.connection.host" : "172.27.11.156"
    "spark.cassandra.output.batch.size.rows" : "auto"
    //"spark.cassandra.username"
    //"spark.cassandra.password"
    //USING THIS CONFIG AFTER RESTART JOB
    //"spark.streaming.kafka.maxRatePerPartition" : "100"
    //STABLE MODE.
    "spark.streaming.kafka.maxRatePerPartition" : "300"
    //es test
    "es.port": "9200"
    "es.nodes":"172.27.11.156"
    "es.http.timeout":"5m"
    "es.scroll.size":"50"
    "es.index.auto.create":"true"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

  //  windowDuration: 120s
  //  slideDuration: 120s
  //  streamingBatchDuration: 60s

  //windowDuration: 270s
  //windowDuration: 1350s
  //slideDuration: 90s
  streamingBatchDuration: 90s
  windowDuration: 90s
  slideDuration: 90s
  //windowDuration: 10s

  //slideDuration: 10s

  //streamingBatchDuration: 5s

  //streamingCheckPointDir: ${java.io.tmpdir}
  //streamingCheckpointDir: "/tmp"
  streamingCheckPointDir: "/build/deploy/checkpoints/anomaly"
  //[Yarn mode]
  //streamingCheckPointDir: "/data/kafka/checkpoint/anomaly"

  //streamingCheckPointDir: "/tmp/streamingCheckPoint6"


  sourceKafka {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    //"bootstrap.servers": "localhost:9092"
    "group.id": "raidus-streaming-log"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"

  }

  cassandraStorage{
    "keySpace" : "radius"
    "table" : "connlog"
  }
  mongoStorage{
    "write.mode":"append"
  }
  powerBIConfig{
    //"bras_dataset_url":"https://api.powerbi.com/beta/4ebc9261-871a-44c5-93a5-60eb590917cd/datasets/e654c506-58c3-42ae-ac37-ddf4fd4ca8d0/rows?key=nrB25hj7BRJZ95pRBSnUiF0QOAGzHkU8i67bcLr%2FAUGiNykfVC%2Bp6yHGxd5Eop4pKpf0Qz4dxWdGPPc7fFRrZg%3D%3D"
    "bras_dataset_url":"https://api.powerbi.com/beta/4ebc9261-871a-44c5-93a5-60eb590917cd/datasets/b62431b5-e77b-4e00-a100-df5f61fcd273/rows?key=m9uGpnXiQAjlZitkd7%2FDZb6RWs1tf5pt2x%2FV7jASBFKfe0aBJEPDRz9hvSWVfik3DhHTqOHLNYP2NYiEr9dSAQ%3D%3D"
    "bras_sumcount_dataset_url":"https://api.powerbi.com/beta/4ebc9261-871a-44c5-93a5-60eb590917cd/datasets/fe2af8f6-da63-4746-8a13-cf388d0b14a8/rows?key=KjN77LjanVtlQe3EFR%2FvY6wHcAvhFtkrgaq3TQXjkO423QO8hr9HgILI4l7eP3EObZ%2FAcT02aMYcR304GVuUCw%3D%3D"
    "inf_dataset_url" :""
    "inf_sumcount_dataset_url":"url hear!"
    "proxy_host":"172.30.45.220"
    "radius_anomaly_point_detect_url":"https://api.powerbi.com/beta/4ebc9261-871a-44c5-93a5-60eb590917cd/datasets/25f3994c-4044-4c97-b586-eab0dec67598/rows?key=pv02o%2FFyA%2BiZ8JvWt2Mj8Tm3WnYFl5VWpGKDm87fOPzbk4KtKouWAHixc3cXWBME7i8amvTEq3WvWggdDEdR9A%3D%3D"
  }
  postgresStorage{
    //"jdbcUsername" : "postgres"
    //"jdbcPassword" : "hung"
    //"jdbcHostname" : "localhost"
    //"jdbcPort"     : "5432"
    //"jdbcDatabase" : "big_data"
    "jdbcUsername" : "infdb"
    //"jdbcUsername" : "rawlog_fe"
    "jdbcPassword" : "inf@db170120"
    //"jdbcPassword" : "Pankjha2jW9JAh5"
    //"jdbcHostname" : "172.27.11.151"
    "jdbcHostname" : "172.27.11.151"
    // "jdbcHostname" : "172.27.11.9"
    "jdbcPort"     : "5432"
    "jdbcDatabase" : "inf_db"
    "jdbcHostnameForRead" : "172.27.11.151"
    //"jdbcHostnameForRead" : "172.27.11.152"
    "jdbcDatabaseForRead" : "big_data"
    "jdbcUsernameForRead" : "big_data_query"
    "jdbcPasswordForRead" : "bdquery"



    //        "jdbcUsername" : "big_data_query"
    //        "jdbcPassword" : "bdquery"
    //        "jdbcHostname" : "172.27.11.152"
    //        "jdbcPort"     : "5432"
    //        "jdbcDatabase" : "big_data"
  }

}

// LOAD CONFIG

loadConfig {
  //Kafka input topic
  input {
    topic: "radiusLoadLog"
  }

  sparkConfig {
    "spark.master": "yarn"
    "spark.app.name": "loadLog-Radius"
    // mongo config
    //"spark.mongodb.output.uri" : "mongodb://172.27.11.146:27017/radius.conn_counting"
    //"spark.mongodb.output.uri" : "mongodb://localhost:27017/radius.conn_counting"
    // cassandra config
    //"spark.cassandra.connection.host" : "172.27.11.156"
    //"spark.cassandra.output.batch.size.rows" : "auto"
    //"spark.cassandra.username"
    //"spark.cassandra.password"
    //USING THIS CONFIG AFTER RESTART JOB
    //"spark.streaming.kafka.maxRatePerPartition" : "100"
    //STABLE MODE.
    "spark.streaming.kafka.maxRatePerPartition" : "300"
    //es test
    "es.port": "9200"
    "es.nodes":"172.27.11.156"
    "es.http.timeout":"5m"
    "es.scroll.size":"50"
    "es.index.auto.create":"true"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

  streamingBatchDuration: 10s
  //streamingBatchDuration: 600s

  streamingCheckPointDir: "/data/kafka/checkpoint/loadLog"
  //streamingCheckPointDir: "/tmp/streamingCheckPoint6"

  sourceKafka {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    //"bootstrap.servers": "localhost:9092"
    "group.id": "raidus-streaming-log"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"

  }


}
//
// IngestConfig


ingestConfig {
  //Kafka input topic

  inputKafkaTopic: "anomalydetection"

  sparkConfig {
    "spark.master": "yarn"
    "spark.app.name": "anomaly-detection-Radius-ingest"
    // mongo config
    //"spark.mongodb.output.uri" : "mongodb://172.27.11.146:27017/radius.conn_counting"
    //"spark.mongodb.output.uri" : "mongodb://localhost:27017/radius.conn_counting"
    // cassandra config
    "spark.cassandra.connection.host" : "172.27.11.156"
    "spark.cassandra.output.batch.size.rows" : "auto"
    //"spark.cassandra.username"
    //"spark.cassandra.password"
    //USING THIS CONFIG AFTER RESTART JOB
    //"spark.streaming.kafka.maxRatePerPartition" : "100"
    //STABLE MODE.
    "spark.streaming.kafka.maxRatePerPartition" : "300"
    //es test
    "es.port": "9200"
    "es.nodes":"172.27.11.156"
    "es.http.timeout":"5m"
    "es.scroll.size":"50"
    "es.index.auto.create":"true"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

  streamingBatchDuration: 30s

  streamingCheckPointDir: "/data/kafka/checkpoint/anomaly_ingest"

  sourceKafka {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    //"bootstrap.servers": "localhost:9092"
    "group.id": "raidus-streaming-log"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"

  }

  cassandraStorage{
    "keySpace" : "radius"
    "table" : "brasscount"
  }


}


//// INF PARSER CONFIG

infConfig {
  //Kafka input topic
  input {
    topic: "inf-rawlogs"
  }

  sparkConfig {
    //"spark.master": "local[2]"
    //PROD
    "spark.master": "yarn"
    "spark.app.name": "inf-Parser"
    // mongo config
    //"spark.mongodb.output.uri" : "mongodb://172.27.11.146:27017/radius.conn_counting"
    //"spark.mongodb.output.uri" : "mongodb://localhost:27017/radius.conn_counting"
    // cassandra config
    "spark.cassandra.connection.host" : "172.27.11.156"
    "spark.cassandra.output.batch.size.rows" : "auto"
    //"spark.cassandra.username"
    //"spark.cassandra.password"
    //USING THIS CONFIG AFTER RESTART JOB
    //"spark.streaming.kafka.maxRatePerPartition" : "100"
    //STABLE MODE.
    "spark.streaming.kafka.maxRatePerPartition" : "300"
    //es test
    "es.port": "9200"
    //"es.nodes":"localhost"
    "es.nodes":"172.27.11.156"
    "es.http.timeout":"5m"
    "es.scroll.size":"50"
    "es.index.auto.create":"true"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

  streamingBatchDuration: 30s
  //streamingBatchDuration: 600s

  //streamingCheckPointDir: "/tmp"
  //PRO
  streamingCheckPointDir: "/data/kafka/checkpoint/infLog"
  //streamingCheckPointDir: "/tmp/streamingCheckPoint6"

  sourceKafka {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"
    //PRO
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    // LOCAL
    //"bootstrap.servers": "localhost:9092"
    "group.id": "raidus-streaming-log"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"

  }
}

//// NOC PARSER CONFIG

nocConfig {
  //Kafka input topic
  input {
    topic: "noc-rawlogs"
  }

  sparkConfig {
    //LOCAL - TEST
    //"spark.master": "local[2]"
    // PRODUCTION
    "spark.master": "yarn"
    "spark.app.name": "noc-Parser"
    // mongo config
    //"spark.mongodb.output.uri" : "mongodb://172.27.11.146:27017/radius.conn_counting"
    //"spark.mongodb.output.uri" : "mongodb://localhost:27017/radius.conn_counting"
    // cassandra config
    //"spark.cassandra.connection.host" : "localhost"
    "spark.cassandra.connection.host" : "172.27.11.156"
    "spark.cassandra.output.batch.size.rows" : "auto"
    //"spark.cassandra.username"
    //"spark.cassandra.password"
    //USING THIS CONFIG AFTER RESTART JOB
    //"spark.streaming.kafka.maxRatePerPartition" : "100"
    //STABLE MODE.
    "spark.streaming.kafka.maxRatePerPartition" : "300"
    //es test
    "es.port": "9200"
    //"es.nodes":"localhost"
    "es.nodes":"172.27.11.156"
    "es.http.timeout":"5m"
    "es.scroll.size":"50"
    "es.index.auto.create":"true"
    //"spark.serializer": "org.apache.spark.serializer.KryoSerializer"
    //"spark.kryo.registrator": "app.WordCountKryoRegistration"
  }

  streamingBatchDuration: 30s
  //streamingBatchDuration: 10s


  //streamingCheckPointDir: "/tmp"
  //[Produc]
  streamingCheckPointDir: "/data/kafka/checkpoint/nocLog"
  // LOCAL
  //streamingCheckPointDir: "/tmp/streamingCheckPointNoc"

  sourceKafka {
    // kafka brokers
    //"metadata.broker.list": "localhost:9092"
    // start from the latest messages (at most once)
    "auto.offset.reset": "latest"

    //PRO-
    "bootstrap.servers": "172.27.11.75:9092,172.27.11.80:9092,172.27.11.85:9092"
    // LOCAL
    //"bootstrap.servers": "localhost:9092"
    "group.id": "raidus-streaming-log"
    //String De
    "key.deserializer" : "org.apache.kafka.common.serialization.StringDeserializer"
    "value.deserializer": "org.apache.kafka.common.serialization.StringDeserializer"
    //Array[Byte]
    //"key.deserializer" : "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //"value.deserializer": "org.apache.kafka.common.serialization.ByteArrayDeserializer"
    //Do not set dererializer for source!!
    //"key.serializer" : "org.apache.kafka.common.serialization.ByteArraySerializer"
    //"value.serializer": "org.apache.kafka.common.serialization.ByteArraySerializer"
  }
}
